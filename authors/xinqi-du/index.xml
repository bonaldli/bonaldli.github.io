<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xinqi Du | Bonald Ziyue LI</title>
    <link>https://bonaldli.github.io/authors/xinqi-du/</link>
      <atom:link href="https://bonaldli.github.io/authors/xinqi-du/index.xml" rel="self" type="application/rss+xml" />
    <description>Xinqi Du</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 18 Mar 2024 14:59:50 +0200</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Xinqi Du</title>
      <link>https://bonaldli.github.io/authors/xinqi-du/</link>
    </image>
    
    <item>
      <title>FELight: Fairness-Aware Traffic Signal Control Via Sample-Efficient Reinforcement Learning</title>
      <link>https://bonaldli.github.io/publication/felight/</link>
      <pubDate>Mon, 18 Mar 2024 14:59:50 +0200</pubDate>
      <guid>https://bonaldli.github.io/publication/felight/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TL; DR&lt;/strong&gt;:  It&amp;rsquo;s traffic signal control again, but what&amp;rsquo;s new here? How can we ensure that the agents control the traffic light fairly? We embedded such fairness metrics into Reinforcement Learning models. Furthermore, how can we minimize the sample required and achieve a resource-efficient agent? We used self-supervised learning!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
